-
- # Conceptual Overview of The "Bitter Lesson" in AI
	- "the bitter lesson" is a core idea in AI that suggests the approaches which ultimately succeed over the long term are those that leverage massive computation and scalable learning, rather than relying on carefully crafted human insight or expert-designed solutions. This insight comes from decades of AI research and was notably articulated by Richard Sutton in his essay "The Bitter Lesson" ([discussion here](https://readwise.io/bookreview/46591902/?highlight=821606396): [(Time 00:24:22)](https://share.snipd.com/snip/606b086c-b744-45b6-90dc-c1c681813c4c)).
	- Specifically, the lesson warns that clever, human-engineered solutions or attempts to insert hand-coded knowledge into AI systems may yield impressive short-term results, but these approaches are eventually outpaced by systems that scale with compute and data, such as deep learning models that eschew detailed human priors ([summarized here](https://readwise.io/bookreview/48402201/?highlight=847762828): [(Time 00:49:55)](https://share.snipd.com/snip/d4b4ef90-5631-412a-8a99-5b880eb6d427)). This is because scalable learning and search algorithms, especially those that take advantage of increased computational resources and large datasets, tend to generalize better and improve further as technology advances ([further explained here](https://readwise.io/bookreview/48402201/?highlight=847762964): [(Time 00:49:24)](https://share.snipd.com/snip/6fb76101-d900-4687-a98b-2196b174c1b4)).
	- Real-world examples of this include chess, where early AI programs attempted to encode vast amounts of human knowledge, only to be surpassed by methods that used deep search and scalable computation. The same arc is now being observed in language models and other areas of AI research, where "scaffolding" or making complex, human-designed additions to models may yield short-term improvements but will likely be abandoned in favor of more scalable approaches ([see this conversation](https://readwise.io/bookreview/46591902/?highlight=821606396): [(Time 00:24:22)](https://share.snipd.com/snip/606b086c-b744-45b6-90dc-c1c681813c4c)). There's a recognition among researchers that "models just want to learn," and providing a simple, scalable architecture—then throwing more compute and data at it—tends to yield superior results over intricate, hand-designed features and interventions ([expanded here](https://readwise.io/bookreview/48402201/?highlight=847762964): [(Time 00:49:24)](https://share.snipd.com/snip/6fb76101-d900-4687-a98b-2196b174c1b4)), ([podcast reference](https://readwise.io/bookreview/51438350/?highlight=890414714): [(Time 01:10:39)](https://share.snipd.com/snip/180286c6-6268-462e-9123-ebcee88db73f)).
	- The lesson also raises caution for fields like multi-agent systems, where some believe current progress is hindered because approaches ignore this scaling-centric, "bitter lesson"-driven path and instead rely too much on heuristics ([example](https://readwise.io/bookreview/52695238/?highlight=905936339): [(Time 00:44:38)](https://share.snipd.com/snip/d2d53d74-a9af-47d0-bda3-dbae725e5e49)).
	- At the same time, there are complexities in applying the lesson—especially in situations where rewards or truth aren't easy to define or compute, as seen in language processing compared to games like Go ([see DeepMind example](https://readwise.io/bookreview/42813028/?highlight=753067547): [(Time 00:22:40)](https://share.snipd.com/snip/c3ef40f3-f3eb-446f-9d26-307732b74ea0)). But the general trend holds: as more compute and data become available, scalable learning wins, and human cleverness (as tempting as it is) is usually overtaken in the end.
	- In summary, "the bitter lesson" is that, although it feels natural to try to apply our own smarts and careful engineering, it's the methods that capitalize on the scale and universality of computers—the simplest, most general approaches coupled with massive computation—that end up winning in the long run ([concise definition and reach](https://readwise.io/bookreview/46591902/?highlight=821606253): [(Time 00:24:52)](https://share.snipd.com/snip/22145c6f-3417-4335-808c-51a65e5b7599)).