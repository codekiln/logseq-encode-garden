# What I learned at the [[AI Engineer Summit 2025 NYC Workshops]]
	- ## What *is* the [[AI Engineer Summit]]?
		- ### How I *found out* about the AI Engineer Summit...
			- #### âš¡ flash back to [[@swyx]]'s [[GraphQL]] presentation at [[Conference/React Boston/2018]] ...
			  `babel-blade`: **solving the GraphQL double declaration Problem**
			  ![image.png](../assets/image_1742292361076_0.png){:height 331, :width 397}
			  [swyx ðŸŒ‰ on X - link](https://x.com/swyx/status/1046108066037583872)
			- [[Wayfair]] threw a great party. Got to know [[Person/Shawn @swyx Wang]], who at that time was working at [[Netlify]] as a DevRel.
			- ... Time Passes ...
			- Now my favorite AI podcast is ... [[The Latent Space Podcast]]
			- {{embed ((67d943c3-9827-4274-9daa-b2069d73d4b0))}}
			- {{embed ((67d9437f-1cc1-4fcd-ac88-d804c5ceb2d6))}}
			- {{embed ((67d947ef-69e5-4848-a652-658077c58cfc))}}
		- ### so, *what* is the AI Engineer Summit?
			- ![AI engineer Summit logo](../assets/image_1742369972123_0.png)
			- #### [[AI Engineer Summit NYC 2025]]
			  {{embed ((67d94f45-ee8f-42df-844b-c8a44d9a3cdd))}}
			- #### This team also runs the [[AI Engineer World's Fair]] 
			  ![AI engineer summit logo image](https://do3z7e6uuakno.cloudfront.net/uploads/event/banner/1141926/c3e9a68496cd678944e07c2a05524e5a.jpg){:height 268, :width 543}
		- ### so, *when* was the AI Engineer Summit?
		  * Thu Feb 20 - **Leadership Track**
		  * Fri Feb 21 - **Engineering Track**
		  * Sat Feb 22 - **Workshops**
		      * *I only attended the workshops this year. Would love to attend the full event in the future*
		- ### *where* was the AI Engineer Summit?
		  *Downtown Manhattan, NYC*
		  ![Pic 02](https://lh3.googleusercontent.com/pw/AP1GczORWCrelrJZQ14tww3H_W-jSQOiXjdsJnjooBRAZNoEMYJr-30qT5JTx166v54hfZz_MbAib7m2W2T4KVTwQuJ19rMeNml8IZcZ-Mx8ifeSpm2VZfU=w1920-h1080){:height 309, :width 512}
		  * **Jay Conference Bryant Park** - 109 W 39th St 
		  * **AWS** -  JFK27 (12 W 39th St)
	- ## How I *got* to the AI engineer summit
	  *Many thanks to the leadership team and employer for sponsoring my attendance* 
	  ![Pic 01](https://lh3.googleusercontent.com/pw/AP1GczO5djwdffkqlOOLllHhHi71Dlj_FX7cnZOmR_kfg7TKolWzZwlJoThxwVs-Zzdv89KsXKeRkLrBZH5-m2iVuLKkNuTdhJVL9ADXd4MLjOUNmXkKtjw=w1920-h1080){:height 382, :width 678}
	      * *Port Authority Bus Terminal*
- # Before [[AIES 25 WS 1 - Building Agents with MCP - Mahesh Murag]]
	- ![Pic 01](https://lh3.googleusercontent.com/pw/AP1GczNTS1VKTShXGqSYGMByy6laT8lL5MddZ3bxjDlsMnJcuZzQitD68um-_Yan2Yl5jpBcXgPO_FrqvzxXTStZfIdCGnL86RGzgkNelzm4V-l8dG2ics0=w1920-h1080){:height 389, :width 747}
	- ## Discussions before the first workshop
		- ### 1/3 [[Person/Junrui (Tom) Hu]]
		  Getting coffee before the first workshop, I met Tom, **AI Lead** at [[HanoverPark]], where he's building **AI portfolio management**, **AI inbox analyzer**, real-time fund metrics, and an investor portal. $1.3 billion in assets under administration. Based out of NYC, he was at the AI Engineering track on Friday as well.
		- ### 2/3 - [[Person/Mike Christensen]]
		  ![Mike Christensen](https://cdn.theorg.com/98b0f36b-2fbe-4f45-ab38-1333b975b92d_thumb.jpg){:height 125, :width 111} 
		  ((67da7fc2-1c1f-46e9-84b0-dee824e45395))
		- ### 3/3 - [[Person/Hayden Harrow]]
		  ![Headless Agents logo](https://headlessagents.ai/headless.webp){:height 130, :width 120} 
		  ((67da7fbe-0f7f-45f0-bac4-27dc498b0387))
- # [[AIES 25 WS 1 - Building Agents with MCP - Mahesh Murag]] - #MCP Talk that went viral
	- ## Context - #MCP #Examples from [[David Ondrej - Build Anything with MCP Agents]]
		- ### #Example 1 - using [[GitHub/MCP]] enable [[CursorAI]] to take actions in GitHub
		  {{video https://www.youtube.com/watch?v=TQsP_PlCY1I&t=205s}}
		- ### #Example 2 - enabling [[CursorAI]] to interact with [[Chrome/DevTools]] with [[AgentDeskAI/GitHub/browser-tools-mcp]]
		  {{video https://www.youtube.com/watch?v=TQsP_PlCY1I&t=806s}}
	- ## What problem does [[Model Context Protocol]] solve?
	  ![MCP problem solved](https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F34123523-7082-4895-b8e4-b26077683c61_1610x868.png){:height 395, :width 718}
		- ### What does this mean ... for [[AI Coding]]? AI Agents in Code editors can now ...
		  * develop technical plans using Jira, Confluence
		  * submit merge requests to GitHub, GitLab, etc
		  * check out a ticket and start working on it
		  * introspect into database, etc
	- ## Side-note - [[Latent Space/Blog/25/03/Why MCP Won]]
		- this talk possibly contributed to MCP going viral in [[2025/03]] 
		  > At current pace,Â **MCP will overtake OpenAPI in July**
		  ![MCP going viral](https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3c23222d-bb03-445b-9806-483eb06c3b75_2554x1640.png)
		- [[Person/Mahesh Murag]]'s talk likely contributed to MCP taking over AI social media feeds
		  ![the twitter hype](https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc325ceca-4bdf-44cf-b727-978bb49a89e1_1106x1716.png){:height 551, :width 299}
	- ## The Problem MCP Solves
		- Before MCP, AI application development was fragmented:
		  * Each team developed custom logic (and prompts!) for integrating data, tools, and context into AI apps.
		  * Significant duplication and complexity within companies.
		  * Difficult to reuse components across AI projects.
	- ## Introducing Model Context Protocol (MCP)
		- MCP standardizes interactions between AI apps (clients) and external systems (servers).
		  ![MCP standardized interactions](../assets/image_1740238166470_0.png){:height 358, :width 684}
		- Inspired by [[GraphQL]] and [[Language Server Protocol]].
		  ![Apis -> LSP -> MCP](https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F287e9c38-db9a-4abb-9a88-bc3e3e590355_2252x1214.png)
		- Three interaction types: Tools, Resources, Prompts.
		  ![Pic 04](https://lh3.googleusercontent.com/pw/AP1GczMbc7nvpyq0Hx6ROTqCkZhH0QkfKv8hlWvL9dVp1rJX7bfbdLeKlOOrYlvwx2oPOJ652WgOhpiu3hV7Kg9eXBEs1tI4d7TzHJ0XgQlciKtax46nag0=w1920-h1080){:height 330, :width 544}
		- A bit clearer
		  ![MCP Deep-Dive](https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe07df610-fa0b-4e18-bca5-6ade934cb64a_2274x1264.png)
	- ## Rapid Adoption of MCP
		- Major companies quickly adopted MCP:
		  * Cloudflare, Shopify, IBM, GitHub, Docker, Replit, and more.
		  * Over 1,100 community-built MCP servers available.
		  * Industry leaders predicting MCP to become standard in AI integration.
		  ![Rapid adoption](https://lh3.googleusercontent.com/pw/AP1GczP4Thkxk-MhVQqm9JdoNSJJnXEiyYdY63F3jsPJVgFoK7Y2HECKVBPS9xXg6sttqCWn-O-4IDyFER4iKyijKOIK0spyAtg4gTrEqxKnHE3xdWqSHjc=w1920-h1080){:height 225, :width 400}
	- ## MCP Components: Tools, Resources, and Prompts
		- ### **Tools** (*Model-controlled*)
		  * LLM knows about the tools it has access to, and uses that to **decide** when to invoke certain actions. These are tiny AI prompts made from a tool schema. Example from [[GitHub MCP]] [here](https://github.com/modelcontextprotocol/servers/blob/main/src/github/index.ts#L65)
			- #### declare the parameters the AI will use to call the `GetFileContents` tool in natural language
			  ```
			  const GetFileContentsSchema = z.object({
			    owner: z.string().describe("Repository owner (username or organization)"),
			    repo: z.string().describe("Repository name"),
			    path: z.string().describe("Path to the file or directory"),
			    branch: z.string().optional().describe("Branch to get contents from"),
			  });
			  ```
			- #### MCP server tools - a list of mappings between descriptions of tools and that tool's implementation in the API
			  ```
			  server.setRequestHandler(..., async () => { return { tools: [ ...{
			    name: "get_file_contents",
			    description: "Get the contents of a file or directory from a GitHub repository",
			    inputSchema: zodToJsonSchema(files.GetFileContentsSchema),
			  }, ...
			  ```
			- #### [[Key Insight]]
			  *AI tools are just a tiny LLM prompt that tells an LLM about something it can do*
			  * "get_file_contents" - supply "Repository owner (username or organization)" and "Repository name" to "Get the contents of a file or directory from a GitHub repository"
		- ### **Resources** (*Application-controlled*)
		  * **shared state** between the [[Agentic System]] and the client application
		    * #Example - in [[ChatGPT/Canvas]], this would be the canvas - both the user and the LLM know about the state of the canvas. 
		  * *NOTE: This is just an example, OpenAI doesn't use MCP for Canvas (yet?)*
		  ![chatgpt canvas](https://images.ctfassets.net/kftzwdyauwt9/uZHfstpnZ78qg2HQhn7m1/25db0387b0f72c0e20c933dcb01533f5/Canvas_Hero.png?w=1080&q=90&fm=webp){:height 155, :width 320}
		- ### **[Prompts](https://modelcontextprotocol.io/docs/concepts/prompts)** (User-controlled):
		  * Predefined, **user-controlled** interactions triggered by users (kinda like slash commands).
		  ![image of prompts](../assets/image_1742381645310_0.png){:height 512, :width 414}
	- ## MCP in Action: Claude AI Integration Demo
		- Claude desktop autonomously:
		  * Identifies and summarizes GitHub issues.
		  * Adds top priority tasks into user's Asana.
		  ![Claude desktop demo](../assets/image_1740239495124_0.png){:height 297, :width 412}
	- ## MCP-Agent Framework (Lastmile.ai)
		- Enables complex multi-agent workflows.
		- Example: Quantum computing cybersecurity research task. 
		  ![MCP-Agent project structure](https://lh3.googleusercontent.com/pw/AP1GczMwwnFzwCmTQrAIOfOJwG_Hz3G5yPrx4P-1i3rBPwtx1IclV5EHvIjjmp6e7ZWYQWVpFU3dN8DwB_FnBChNN3AMkZytcjAQdmvT4gaKVgKYC_8gx5k=w1920-h1080){:height 381, :width 657}
		  * Uses **sub-agents**: research, fact-checker, report writer
		  * side note - [[People/Mahesh Murag]] uses [[Windsurf]] here
	- ## MCP & Augmented LLM Concept
		- MCP enhances LLMs, allowing dynamic tool discovery.
		- Enables agents to evolve post-deployment without manual updates.
		  ![Augmented LLM](../assets/image_1740240522201_0.png){:height 225, :width 400}
	- ## MCP Composability & Sampling
		- Supports hierarchical agent workflows:
		  * Agents act as both MCP clients and servers.
		  * Sampling allows servers to request inference from clients, ensuring control of privacy and cost.
		  ![Hierarchical agent diagram](../assets/image_1740241876883_0.png){:height 225, :width 400}
	- ## MCP Inspector & OAuth Authentication
		- Inspector provides debugging for MCP connections.
		- OAuth integration simplifies secure service authentication.
		  ![MCP Inspector OAuth](../assets/image_1740242601017_0.png){:height 225, :width 400}
	- ## MCP Registry API: Autonomous Discovery
		- Official MCP Registry simplifies finding and trusting servers.
		- Example: Agent autonomously finds Grafana MCP server for debugging tasks.
		  ![MCP Registry discovery](../assets/image_1740242405280_0.png){:height 225, :width 400}
	- ## Server Discovery: `.well-known/mcp.json`
		- Websites expose MCP server info publicly.
		- Agents instantly discover services like Shopify MCP integration.
		  ![Shopify MCP discovery](../assets/image_1740243306243_0.png){:height 225, :width 400}
	- ## MCP Roadmap: Future Features
		- Upcoming improvements:
		  * Stateful vs. stateless connections
		  * Real-time data streaming
		  * Namespacing tools
		  * Proactive, event-driven servers
		  ![MCP Future roadmap](../assets/image_1740243402170_0.png){:height 225, :width 400}
	- ## Key Takeaways
		- MCP is quickly becoming foundational for AI development.
		- Standardization boosts innovation and interoperability.
		- Strong and growing industry adoption.
-